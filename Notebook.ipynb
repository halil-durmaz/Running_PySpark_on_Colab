{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solution---PySpark_on_Colab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UMWDQVLbYOj"
      },
      "source": [
        "# <font color=\"red\"> <font size = 10px> PySpark - Required settings </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_BKS4xmpqoK"
      },
      "source": [
        "- Install the requirements (This cell must be run, each time you sign in to Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugFNkousn7br"
      },
      "source": [
        "!apt-get install    openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q            https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz   # New version is released? Paste the download URL\n",
        "!tar xf             spark-3.2.1-bin-hadoop3.2.tgz                                              # Update this with the help from \"!wget -q\" line\n",
        "!pip install -q     findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p3wN86cp7fw"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "- Assign the locations of Java and Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv_h4zP0p8FP"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"                                 # Update this with the help from \"!wget -q\" line"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaO2vF6kqNIu"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "- Start the Spark session. When its done, your Colab environment is ready to run PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KuLvIwVqNvt"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMzR1Awann4"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# <font color=\"red\"> <font size = 10px> Code now </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzmH4TyeaBEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}